{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自然言語\n",
    "\n",
    "人間によって日常の意思疎通のために用いられる、文化的背景を持って自然に発展してきた言語である。\n",
    "\n",
    "自然言語をプログラムで扱うときは、必ず数値化（ベクトル化）してやる必要がある。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用語解説\n",
    "\n",
    "* コーパス：テキストや発話を大規模に集めてデータベース化した言語資料\n",
    "* 形態素解析：文章を一つずつ品詞分解して文章がどのような単語で構成されていて、どのような意味を持つかを判断\n",
    "* Ngram：N文字づつ文字を取り出す。検索インデックス作成などに用いられる\n",
    "* bag-of-words：文書中に単語が含まれるか否かを判定する。01の場合もあるし、個数を含む場合もある\n",
    "* 固有表現抽出：固有名詞を抽出してくる\n",
    "* 構造解析(係り受け)：「黒い眼の大きい少女」の「黒い」と「大きい」はどこにかかるのか\n",
    "* 文脈解析：「スーパーに行った。そこで、リンゴを買った」の「そこ」が何を表すか\n",
    "* 意味解析：上述「黒い」と「大きい」が本来どちらにかかるのが正しいのかを、前後の文脈より判断する"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagof-Words\n",
    "\n",
    "最も基本的な「文章→ベクトル」に変換する手法である。\n",
    "\n",
    "**文A：**私は、東京へ観光に行きました。\n",
    "\n",
    "**文B：**私は、美容院へ行きたい。\n",
    "\n",
    "----\n",
    "私　　　　　→[1,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "は　　　　　→[0,1,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "、　　　　　→[0,0,1,0,0,0,0,0,0,0,0]\n",
    "\n",
    "東京　　　　→[0,0,0,1,0,0,0,0,0,0,0]\n",
    "\n",
    "へ　　　　　→[0,0,0,0,1,0,0,0,0,0,0]\n",
    "\n",
    "観光　　　　→[0,0,0,0,0,1,0,0,0,0,0]\n",
    "\n",
    "に　　　　　→[0,0,0,0,0,0,1,0,0,0,0]\n",
    "\n",
    "行きました　→[0,0,0,0,0,0,0,1,0,0,0]\n",
    "\n",
    "。　　　　　→[0,0,0,0,0,0,0,0,1,0,0]\n",
    "\n",
    "美容院　　　→[0,0,0,0,0,0,0,0,0,1,0]\n",
    "\n",
    "行きたい　　→[0,0,0,0,0,0,0,0,0,0,1]\n",
    "\n",
    "----\n",
    "\n",
    "**文A：**私は、東京へ観光に行きました。\n",
    "\n",
    "**[1,1,1,1,1,1,1,1,1,0,0]**\n",
    "\n",
    "**文B：**私は、美容院へ行きたい。\n",
    "\n",
    "**[1,1,1,0,0,0,0,0,1,1,1]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngram\n",
    "\n",
    "任意の文字列や文書を連続したn個の文字で分割するテキスト分割方法。\n",
    "\n",
    "簡易な検索インデックス作成などに用いられる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['私は、', 'は、先', '、先週', '先週の', '週の日', 'の日曜', '日曜日', '曜日に', '日に、', 'に、東', '、東京', '東京へ', '京へ観', 'へ観光', '観光へ', '光へ行', 'へ行き', '行きま', 'きまし', 'ました']\n"
     ]
    }
   ],
   "source": [
    "text='私は、先週の日曜日に、東京へ観光へ行きました。'\n",
    "\n",
    "def get_ngram(text,n):\n",
    "    '''Ngramを取得する\n",
    "    引数：\n",
    "    　text：処理したい自然言語\n",
    "    　n：取り出したい文字数\n",
    "    返り値：\n",
    "    　ngram_list：単語が格納されたリスト\n",
    "    処理概要：\n",
    "    　文字列と数値を受け取り、Ngramリストを返す\n",
    "    '''\n",
    "    ngram=[]\n",
    "    sub_text=''\n",
    "    for i in range(len(text)-n):\n",
    "        ngram.append(text[i:i+n])\n",
    "    \n",
    "    return ngram\n",
    "\n",
    "ngram = get_ngram(text,3)\n",
    "print(ngram)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 形態素解析\n",
    "\n",
    "文法的な情報の注記の無い自然言語のテキストデータから、辞書と呼ばれる単語の品詞情報にもとづき、言語で意味を持つ最小単位（形態素）に分割し、品詞等を判別する作業である。\n",
    "\n",
    "## 有名な形態素解析エンジン\n",
    "\n",
    "janome：環境構築が容易で、学習用に用いられる\n",
    "\n",
    "mecab：充実した辞書で、最新の単語も随時更新されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリ読み込み\n",
    "from janome.tokenizer import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "すもも\t名詞,一般,*,*,*,*,すもも,スモモ,スモモ\n",
      "================\n",
      "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "================\n",
      "もも\t名詞,一般,*,*,*,*,もも,モモ,モモ\n",
      "================\n",
      "も\t助詞,係助詞,*,*,*,*,も,モ,モ\n",
      "================\n",
      "もも\t名詞,一般,*,*,*,*,もも,モモ,モモ\n",
      "================\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "================\n",
      "うち\t名詞,非自立,副詞可能,*,*,*,うち,ウチ,ウチ\n"
     ]
    }
   ],
   "source": [
    "# インスタンス化\n",
    "t = Tokenizer()\n",
    "\n",
    "# 形態素解析\n",
    "text = 'すもももももももものうち'\n",
    "for token in t.tokenize(text):\n",
    "    print('================')\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================\n",
      "私\t名詞,代名詞,一般,*,*,*,私,ワタシ,ワタシ\n",
      "================\n",
      "は\t助詞,係助詞,*,*,*,*,は,ハ,ワ\n",
      "================\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "================\n",
      "先週\t名詞,副詞可能,*,*,*,*,先週,センシュウ,センシュー\n",
      "================\n",
      "の\t助詞,連体化,*,*,*,*,の,ノ,ノ\n",
      "================\n",
      "日曜日\t名詞,副詞可能,*,*,*,*,日曜日,ニチヨウビ,ニチヨービ\n",
      "================\n",
      "に\t助詞,格助詞,一般,*,*,*,に,ニ,ニ\n",
      "================\n",
      "、\t記号,読点,*,*,*,*,、,、,、\n",
      "================\n",
      "東京\t名詞,固有名詞,地域,一般,*,*,東京,トウキョウ,トーキョー\n",
      "================\n",
      "へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n",
      "================\n",
      "観光\t名詞,サ変接続,*,*,*,*,観光,カンコウ,カンコー\n",
      "================\n",
      "へ\t助詞,格助詞,一般,*,*,*,へ,ヘ,エ\n",
      "================\n",
      "行き\t動詞,自立,*,*,五段・カ行促音便,連用形,行く,イキ,イキ\n",
      "================\n",
      "まし\t助動詞,*,*,*,特殊・マス,連用形,ます,マシ,マシ\n",
      "================\n",
      "た\t助動詞,*,*,*,特殊・タ,基本形,た,タ,タ\n",
      "================\n",
      "。\t記号,句点,*,*,*,*,。,。,。\n"
     ]
    }
   ],
   "source": [
    "# インスタンス化\n",
    "t = Tokenizer()\n",
    "\n",
    "# 形態素解析\n",
    "text = '私は、先週の日曜日に、東京へ観光へ行きました。'\n",
    "for token in t.tokenize(text):\n",
    "    print('================')\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Janome公式\n",
    "\n",
    "https://mocobeta.github.io/janome/api/janome.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 実際の使い方\n",
    "\n",
    "**Ngram：**使い道はそう多くはありませんが、前述したとおり、辞書が手元にない状態でも、簡易な辞書的なものを作れますし、長い複数の文書からNgramを作成すると、各文書で多く出現するNgramは、その文書の特徴を表しますので、クラスタリングなどにも用いることが出来ます。\n",
    "\n",
    "**形態素解析：**ほとんどの場合、このアルゴリズム単体では用いません。形態素解析で、品詞ごとに分解し、固有表現抽出に利用したり、この後の講座で実施する「word2vec(単語のベクトル化)」や「TFIDF(単語の重要度推定)」で使用するデータセットの作成などに利用します。\n",
    "\n",
    "**固有表現抽出：**例えば、OCR(光学認識)で読み込んだ文字列の中から、店舗名を見つけてきたり出来ます。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
