{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 文書生成\n",
    "\n",
    "NNを利用して、自動文書生成を行います。\n",
    "\n",
    "LSTMを用いますので、詳細は、「時系列講座」で解説しております。\n",
    "\n",
    "https://ai-lab.lapras.com/nlp/text-generation-2019/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 必要ライブラリの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM,Dense, Activation\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import LambdaCallback\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データ生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文字の数: 169025\n"
     ]
    }
   ],
   "source": [
    "# データの読み込み\n",
    "with open('./data/sanshiro.txt', encoding='sjis') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# ファイル整形\n",
    "import re\n",
    "text = re.split('\\-{5,}',text)[2]\n",
    "text = re.split('底本：',text)[0]\n",
    "text = text.replace('|', '')\n",
    "text = re.sub('《.+?》', '', text)\n",
    "text = re.sub('［＃.+?］', '',text)\n",
    "text = re.sub('\\n\\n', '\\n', text) \n",
    "text = re.sub('\\n', '', text) \n",
    "text = re.sub('\\r', '', text)\n",
    "text = re.sub('　', '', text)\n",
    "text = re.sub(' ', '', text)\n",
    "\n",
    "print('文字の数:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ユニーク文字の数: 2023\n"
     ]
    }
   ],
   "source": [
    "# ユニークな文字\n",
    "chars = sorted(list(set(text)))\n",
    "print('ユニーク文字の数:', len(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ユニークな文字を辞書に（逆引き辞書も作成）\n",
    "# 鍵は昇順にした際のインデックス番号\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成した説明変数と目的変数の数： 169017\n"
     ]
    }
   ],
   "source": [
    "# 説明変数：分全体をN文字ごとに区切る\n",
    "# 目的変数：区切った際の次の文字\n",
    "\n",
    "# 何文字ごとに区切るか\n",
    "maxlen = 8\n",
    "\n",
    "# 何文字飛ばしにするか\n",
    "step = 1\n",
    "\n",
    "# 説明変数\n",
    "sentences = []\n",
    "\n",
    "# 目的変数\n",
    "next_chars = []\n",
    "\n",
    "# 格納開始\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('生成した説明変数と目的変数の数：', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数と目的変数を数値に変換(Bag-of-Words)\n",
    "\n",
    "# 空の配列作成\n",
    "'''\n",
    "【説明変数】\n",
    "下記、データセットの長さ分ある\n",
    "[\n",
    "    [True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True] # 1文字目\n",
    "    [True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True] # 2文字目\n",
    "    [True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True] # 3文字目\n",
    "    [True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True] # 4文字目\n",
    "    [True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True] # 5文字目\n",
    "    [True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True] # 6文字目\n",
    "    [True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True] # 7文字目\n",
    "    [True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True] # 8文字目\n",
    "]\n",
    "\n",
    "【目的変数】\n",
    "下記、データセットの長さ分ある\n",
    "[True or Falseがユニーク文字数分（2059個）入っている。該当文字の所だけ、True]\n",
    "'''\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "\n",
    "# 格納開始\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1 # 上記で作成した辞書を使用し、該当インデックスを引っ張てくる\n",
    "    y[i, char_indices[next_chars[i]]] = 1 # 上記で作成した辞書を使用し、該当インデックスを引っ張てくる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデル作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデル定義\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# 学習設定\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コールバック関数の作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    '''epoch毎に呼ばれるコールバック関数\n",
    "    処理概要：\n",
    "    　「一うとうととして」から始まる文章を生成し、出力する。\n",
    "    '''\n",
    "    # diversity数字が大きくなるにしたがって、予測確率の低い文字も一定の割合で採用する。\n",
    "    for diversity in [0.2]:\n",
    "        # 生成した文書を格納(毎回「一うとうととして」から始める)\n",
    "        sentence = sentences[0]\n",
    "        generated = sentences[0]\n",
    "        sys.stdout.write(generated)\n",
    "        # 何文字生成するか\n",
    "        num_char = 400\n",
    "        for i in range(num_char):\n",
    "            # 予測用の説明変数作成\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "            # 予測値の算出\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            # 次の文字のインデックスを求める\n",
    "            next_index = sample(preds, diversity)\n",
    "            # 逆引き辞書を用いて、該当インデックスの文字を求める\n",
    "            next_char = indices_char[next_index]\n",
    "            # 文書を生成していく\n",
    "            generated += next_char\n",
    "            # 次の予測に用いる説明変数の基となる文章\n",
    "            sentence = sentence[1:] + next_char\n",
    "            # 出力\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "def sample(preds, diversity=1.0):\n",
    "    '''一定割合で変動させながら、最適なインデックスを返す。\n",
    "    引数：\n",
    "    　preds：予測値の配列\n",
    "    　diversity：どのくらいの割合で、確度の低い文字を採用するか\n",
    "    返り値：\n",
    "    　max_index：最大値のインデックス\n",
    "    '''\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / diversity\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    preds = np.random.multinomial(1, preds, 1)\n",
    "    max_index = np.argmax(preds)\n",
    "    return max_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "169017/169017 [==============================] - 23s 137us/step - loss: 3.3428\n",
      "一うとうととしている。「あなたは、それから、「このあいだの女はこのあいだに、「このあいだの女は、この時三四郎はまたあいだのと、「ええ、それから、「それは、それから三四郎の言った。「このあいだには、「あなたは、あなたのから、どうして、「このあいだの女は、この時からの手を見た。「どうです」「それはいいから、この時には、「ええ、いつのには、この時三四郎は、「どうもならない。それから三四郎の言った。「どうです」「それから、それから、この時三四郎はまたことを言う。「それでも、それから、「それです」「どうかしている。「それでも、どうもしている。三四郎はまた言った。「ええ、それから、「それでもならない。それから三四郎の言った。「どうも、あなたは、それから、この時三四郎はまたある。三四郎はまたない。三四郎はまた言った。「それから、それから、いつのには、この時三四郎はまたない。どうもしている。三四郎はまたあいだに、「あなたEpoch 2/6\n",
      "169017/169017 [==============================] - 23s 137us/step - loss: 3.1984\n",
      "一うとうととしている。その時三四郎はこのあいだには、また、あの女のところへ行った。その時三四郎はこのあいだには、このあいだのはじめて、その時には、このあいだには、その時には、ああ、その時にはじっとして、その時には、このあいだには、それでも、そのあいだには、「あなたは、その時三四郎はこのあいだにものだから、その時三四郎はこのあいだには、このあいだにはなる。その時三四郎はこの時には、あるから、あなただから、その時には、ああ、あの女のようにしている。その時三四郎はこのあいだには、その時三四郎はこのあいだには、みんなために、その時には、その時三四郎はまたない。三四郎はまた、あなたは、その時三四郎はその時には、このあいだには、ああなるかもしれない。その時三四郎は、その時には、ああいう言葉をかいた。「あるから」「そうですか」と言う。「それから、ああなるかもしれない。その時はじめて、「おもしろい。その時三四郎はこの時にEpoch 3/6\n",
      "169017/169017 [==============================] - 23s 136us/step - loss: 3.0798\n",
      "一うとうととしている。三四郎はこのあいだのようになって、そのうちの三四郎は、こんなことを言った。「そういうわけでもない。そのうちの一人です」「そういうわからない。三四郎は、そのうちのようになっている。三四郎は、その時間が、そのうちの与次郎は、その時間が、そのうちのようになっている。そのうちのようになって、そのうちのあいだのは、そのいるかもしれない。そのうちのようになっている。三四郎は、そのうちのようにしている。三四郎はその時のようにしている。三四郎は、その時分にはいった。三四郎はこの女の所へ行くと、そのうちの、「そういうわけでもない。それから、この男は、「どうです」と言った。「そんなものだから、そのうちのようになっている。三四郎は、すると、「そういうわからない。三四郎はこの時のようになっている。三四郎はこの時間の、「ああありが、そのなかにものうと思っている。三四郎はこの時の前にある。「そういうわけでもないEpoch 4/6\n",
      "169017/169017 [==============================] - 23s 136us/step - loss: 2.9906\n",
      "一うとうととしている。三四郎は、このあいだから、その時三四郎は、その時間には、三四郎の方へ出した。「どうもありません」「いいえ」「いいえ」「いいえ」「なに、そうして、そのまたまたいいものである。三四郎はこのあいだには、その時間には、あの女は、その時間には、あの女はその時間には、ああいうことを聞いた。「いつまでも、そうして、その時三四郎の方へ出した。「どうも、こういうことになる。三四郎はこのあいだには、その時間には、あの女は、その時三四郎の方へ出して、「ああ、あなたは、その時間には、あなたは三四郎の方へ出して、「ああ、あなたは、その時間には、あなたの所へ行っている。その時三四郎は、その時三四郎の手になっている。その時三四郎は、その時三四郎の方へ出した。「なに、そういうことを聞いた。三四郎はこのあいだには、それが三四郎にはいった。三四郎は、このあいだには、このあいだはなんだか、「いつまでも、そうして、そのまたEpoch 5/6\n",
      "169017/169017 [==============================] - 23s 138us/step - loss: 2.9137\n",
      "一うとうととしている。そのうちのは、あなたは、その時間が、まだある。それでいて、すわっている。三四郎はこの時には、「そうです」と言った。「あなたは、その時三四郎はこのあいだに、そのうちのまん中に、「ありません」と言った。「ありません」と言った。「どうもありません」「そうです」と言った。「ありません」と言った。「そうして、そうである。「そういうわけでもなかった。そうして、「どうだ」と言った。「どうして、そうですかという。そのうちのまん中に、そのうしろには、「あなたは、その時三四郎はこの時にはただと言って、そうして、「あなたは、そういうが、このあいだから、そのうちのは、その時間が、三四郎にはただ「ありません」と言った。「そうして、そうである。そうして、このあいだから、その時はじめて、その時間が、三四郎はこのあいだから、そのあいだから、あの女はこのあいだから、この時には、「なぜ」と言った。「ありません」と言ったEpoch 6/6\n",
      "169017/169017 [==============================] - 23s 137us/step - loss: 2.8498\n",
      "一うとうととしている。三四郎はこの時には、「ありがとう」と言った。「それで、それでも、いいかげんになって、その時には、「ありがとう」と言った。「あなたは、あなたは、あなたにもしいんだから、それより、この時にはいったら、そのうちのようなものだから、それから、「おい」と言った。「それでも、そういうでも、あの女のようなものだから、それから、「どうも、ありがとうとして、その時には、その時には、「それでも、あなたは、その時には、「ありがとう」「どういうところに、それで、そのうちのあいだのと、すぐにきた。それでもうまいかと思って、「ありがとう」と言った。「ありません」「そういうということである。三四郎はこの時のようなものを、このあいだから、それよりこれで、「ありがとう」と言った。「それで、それで、その時には、この、三四郎には、それよりも、「おいちょっとおいて、このあいだのようなもので、「ありがとう」「そうですか」「い"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x, \n",
    "    y,\n",
    "    batch_size=128,\n",
    "    epochs=6,\n",
    "    callbacks=[\n",
    "        LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習状況の可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAWoUlEQVR4nO3df3Bd5X3n8ffHtkAIDM7aamGt2CKQAWwHG0VxYfAUapiMyU+SNBOCgF1KR3iGoWQ26caLaRvIepaEbn5AsgFNfiwZbkk9JJmmbqnrFhjqEOzKv8E/aibBjjamFu4ANgoE2d/94xwbWZGse+V7dXQffV4zd849z33OOd8jjz969Jxz71VEYGZm9W9S0QWYmVl1ONDNzBLhQDczS4QD3cwsEQ50M7NEONDNzBLhQLdkSJos6ZCkWdXsO4o6/qek/1vt/ZqNZErRBdjEJenQgNUm4E3gcL5+a0SUKtlfRBwGzqh2X7N64UC3wkTEsUCV9CLwxxHxT8P1lzQlIvrHojazeuQpFxu38qmLv5b0qKSDwA2SLpP0rKRXJO2TdL+khrz/FEkhqTVffyR//XFJByX9TNK5lfbNX79G0r9JelXSA5J+Kum/lnke10p6Pq/5CUkXDHjtTkm/kvSapJ2SrszbL5W0MW//d0n3VeFHaolzoNt49zHgr4CzgL8G+oE7gBnA5cAS4NYTbH898GfAfwL2Al+stK+k3wFWAn+aH/cXwMJyipd0EfAIcDvQDPwT8LeSGiTNzWtvi4gzgWvy4wI8ANyXt58PPFbO8Wxic6DbeLc2Iv42Io5ExK8j4l8jYl1E9EfEz4Eu4IoTbP9YRHRHxFtACVgwir4fAjZHxN/kr30VeLnM+q8DfhIRT+Tb3gucCfwe2S+nRmBuPp30i/ycAN4C3i1pekQcjIh1ZR7PJjAHuo13vxy4IulCSX8n6SVJrwH3kI2ah/PSgOd9nPhC6HB9//PAOiL7RLueMmo/uu2eAdseybedGRG7gM+SncP+fGrp7LzrzcAcYJek9ZI+UObxbAJzoNt4N/jjQB8CngPOz6cj/hxQjWvYB7QcXZEkYGaZ2/4KmD1g20n5vv4fQEQ8EhGXA+cCk4H/lbfviojrgN8B/jfwQ0mNJ38qljIHutWbqcCrwOv5/PSJ5s+rZRXQJunDkqaQzeE3l7ntSuAjkq7ML97+KXAQWCfpIkl/IOlU4Nf54zCApBslzchH9K+S/WI7Ut3TstQ40K3efBb4L2Sh+BDZhdKaioh/Bz4FfAU4AJwHbCK7b36kbZ8nq/dbQC/ZRdyP5PPppwJfJpuPfwl4B3BXvukHgB353T1/CXwqIn5TxdOyBMlfcGFWGUmTyaZS/jAi/qXoesyO8gjdrAySlkg6K58e+TOyO1TWF1yW2XEc6GblWQT8nGx6ZAlwbUSMOOViNpY85WJmlgiP0M3MElHYh3PNmDEjWltbizq8mVld2rBhw8sRMeRts4UFemtrK93d3UUd3sysLknaM9xrnnIxM0uEA93MLBEOdDOzRPgbi8zsmLfeeouenh7eeOONokuZ8BobG2lpaaGhoaHsbRzoZnZMT08PU6dOpbW1lexDJa0IEcGBAwfo6enh3HPPHXmDXF1NuZRK0NoKkyZly1JFXyFsZiN54403mD59usO8YJKYPn16xX8p1c0IvVSCzk7o68vW9+zJ1gE6Ooqryyw1DvPxYTT/DnUzQl++/O0wP6qvL2s3M7M6CvS9eytrN7P6c+DAARYsWMCCBQs4++yzmTlz5rH13/ymvI+Dv/nmm9m1a9cJ+3zzm9+kVKU520WLFrF58+aq7Otk1c2Uy6xZ2TTLUO1mVoxSKfsree/e7P/iihUnNwU6ffr0Y+H4hS98gTPOOIPPfe5zx/WJCCKCSZOGHo9+73vfG/E4t9122+iLHMfqZoS+YgU0NR3f1tSUtZvZ2Dt6XWvPHoh4+7pWLW5WeOGFF5g3bx5Lly6lra2Nffv20dnZSXt7O3PnzuWee+451vfoiLm/v59p06axbNky5s+fz2WXXcb+/fsBuOuuu/ja1752rP+yZctYuHAhF1xwAc888wwAr7/+Op/4xCeYP38+n/70p2lvbx9xJP7II4/wnve8h3nz5nHnnXcC0N/fz4033nis/f777wfgq1/9KnPmzGH+/PnccMMNVfk51U2gd3RAVxfMng1Stuzq8gVRs6KM9XWt7du3c8stt7Bp0yZmzpzJvffeS3d3N1u2bGHNmjVs3779t7Z59dVXueKKK9iyZQuXXXYZ3/3ud4fcd0Swfv167rvvvmO/HB544AHOPvtstmzZwrJly9i0adMJ6+vp6eGuu+7iySefZNOmTfz0pz9l1apVbNiwgZdffplt27bx3HPPcdNNNwHw5S9/mc2bN7Nlyxa+8Y1vnORPJ1M3gQ5ZeL/4Ihw5ki0d5mbFGevrWueddx7ve9/7jq0/+uijtLW10dbWxo4dO4YM9NNOO41rrrkGgPe+9728+OKLQ+774x//+G/1Wbt2Lddddx0A8+fPZ+7cuSesb926dSxevJgZM2bQ0NDA9ddfz9NPP83555/Prl27uOOOO1i9ejVnnXUWAHPnzuWGG26gVCpV9OahE6mrQDez8WO461e1uq51+umnH3u+e/duvv71r/PEE0+wdetWlixZMuQ926eccsqx55MnT6a/v3/IfZ966qm/1afSL/8Zrv/06dPZunUrixYt4v777+fWW28FYPXq1SxdupT169fT3t7O4cOHKzreUBzoZjYqRV7Xeu2115g6dSpnnnkm+/btY/Xq1VU/xqJFi1i5ciUA27ZtG/IvgIEuvfRSnnzySQ4cOEB/fz8/+MEPuOKKK+jt7SUi+OQnP8ndd9/Nxo0bOXz4MD09PSxevJj77ruP3t5e+gbPX41C3dzlYmbjy9Epz2re5VKutrY25syZw7x583jXu97F5ZdfXvVj3H777dx0001cfPHFtLW1MW/evGPTJUNpaWnhnnvu4corryQi+PCHP8wHP/hBNm7cyC233EJEIIkvfelL9Pf3c/3113Pw4EGOHDnC5z//eaZOnXrSNRf2naLt7e3hL7gwG1927NjBRRddVHQZ40J/fz/9/f00Njaye/du3v/+97N7926mTBm7cfBQ/x6SNkRE+1D9PUI3MxvCoUOHuOqqq+jv7ycieOihh8Y0zEdjfFdnZlaQadOmsWHDhqLLqIgviprZcYqahrXjjebfwYFuZsc0NjZy4MABh3rBjn4eemNjY0XbecrFzI5paWmhp6eH3t7eokuZ8I5+Y1ElRgx0SY3A08Cpef/HIuIvBvX5KPBF4AjQD3wmItZWVImZFa6hoaGib8ix8aWcEfqbwOKIOCSpAVgr6fGIeHZAn38GfhIRIeliYCVwYQ3qNTOzYYwY6JFNph3KVxvyRwzqc2jA6umDXzczs9or66KopMmSNgP7gTURsW6IPh+TtBP4O+CPhtlPp6RuSd2eozMzq66yAj0iDkfEAqAFWChp3hB9fhwRFwLXks2nD7Wfrohoj4j25ubmk6nbzMwGqei2xYh4BXgKWHKCPk8D50macXKlmZlZJUYMdEnNkqblz08DrgZ2DupzvvKvqJbUBpwCHKh+uWZmNpxy7nI5B3hY0mSyXwArI2KVpKUAEfEg8AngJklvAb8GPhV+Z4KZ2Zjypy2amdWRE33aot/6b2aWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZokYMdAlNUpaL2mLpOcl3T1Enw5JW/PHM5Lm16ZcMzMbTjkj9DeBxRExH1gALJF06aA+vwCuiIiLgS8CXdUtc+IqlaC1FSZNypalUtEVmdl4NWWkDhERwKF8tSF/xKA+zwxYfRZoqVaBE1mpBJ2d0NeXre/Zk60DdHQUV5eZjU9lzaFLmixpM7AfWBMR607Q/Rbg8WoUN9EtX/52mB/V15e1m5kNVlagR8ThiFhANvJeKGneUP0k/QFZoH9+mNc7JXVL6u7t7R1tzRPG3r2VtZvZxFbRXS4R8QrwFLBk8GuSLga+DXw0Ig4Ms31XRLRHRHtzc/Moyp1YZs2qrN3MJrZy7nJpljQtf34acDWwc1CfWcCPgBsj4t9qUehEtGIFNDUd39bUlLWbmQ024kVR4BzgYUmTyX4BrIyIVZKWAkTEg8CfA9OB/yMJoD8i2mtU84Rx9MLn8uXZNMusWVmY+4KomQ1F2U0sY6+9vT26u7sLObaZWb2StGG4AbPfKWpmlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJcKCbmSXCgW5mlggHuplZIhzoZmaJGDHQJTVKWi9pi6TnJd09RJ8LJf1M0puSPlebUs3M7ESmlNHnTWBxRByS1ACslfR4RDw7oM9/AH8CXFuLIs3MbGQjjtAjcyhfbcgfMajP/oj4V+Ct6pdoZmblKGsOXdJkSZuB/cCaiFhX27LMzKxSZQV6RByOiAVAC7BQ0rzRHExSp6RuSd29vb2j2YWZmQ2jortcIuIV4ClgyWgOFhFdEdEeEe3Nzc2j2YWZmQ2jnLtcmiVNy5+fBlwN7Kx1YWZmVply7nI5B3hY0mSyXwArI2KVpKUAEfGgpLOBbuBM4IikzwBzIuK1WhVuZmbHGzHQI2IrcMkQ7Q8OeP4S2fy6mZkVxO8UtXGnVILWVpg0KVuWSkVXZFYfyplyMRszpRJ0dkJfX7a+Z0+2DtDRUVxdZvXAI3QbV5YvfzvMj+rry9rN7MQc6Dau7N1bWbuZvc2BbuPKrFmVtZvZ2xzoNq6sWAFNTce3NTVl7WZ2Yg50G1c6OqCrC2bPBilbdnX5gqhZOXyXi407HR0OcLPR8AjdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRDnQzs0Q40M3MEuFANzNLxIiBLqlR0npJWyQ9L+nuIfpI0v2SXpC0VVJbbco1M7PhTCmjz5vA4og4JKkBWCvp8Yh4dkCfa4B354/fA76VL83MbIyMOEKPzKF8tSF/xKBuHwW+n/d9Fpgm6ZzqlmpmZidS1hy6pMmSNgP7gTURsW5Ql5nALwes9+Rtg/fTKalbUndvb+9oazZLTqkEra0waVK2LJWKrsjqUVmBHhGHI2IB0AIslDRvUBcNtdkQ++mKiPaIaG9ubq68WrMElUrQ2Ql79kBEtuzsdKhb5Sq6yyUiXgGeApYMeqkHeOeA9RbgVydVmdkEsXw59PUd39bXl7WbVaKcu1yaJU3Ln58GXA3sHNTtJ8BN+d0ulwKvRsS+qldrlqC9eytrNxtOOXe5nAM8LGky2S+AlRGxStJSgIh4EPh74APAC0AfcHON6jVLzqxZ2TTLUO1mlRgx0CNiK3DJEO0PDngewG3VLc1sYlixIpszHzjt0tSUtZtVwu8UNStYRwd0dcHs2SBly66urN2sEuVMuZhZjXV0OMDt5HmEbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJtZIUolaG2FSZOyZalUdEX1b0rRBZjZxFMqQWcn9PVl63v2ZOsAHR3F1VXvPEI3szG3fPnbYX5UX1/WbqPnQDezMbd3b2XtVh4HupmNuVmzKmu38jjQzWzMrVgBTU3HtzU1Ze02eiMGuqR3SnpS0g5Jz0u6Y4g+75D0Y0lbJa2XNK825ZpZCjo6oKsLZs8GKVt2dfmC6Mkq5y6XfuCzEbFR0lRgg6Q1EbF9QJ87gc0R8TFJFwLfBK6qQb1mloiODgd4tY04Qo+IfRGxMX9+ENgBzBzUbQ7wz3mfnUCrpN+tcq1mZnYCFc2hS2oFLgHWDXppC/DxvM9CYDbQMsT2nZK6JXX39vaOpl4zMxtG2YEu6Qzgh8BnIuK1QS/fC7xD0mbgdmAT2VTNcSKiKyLaI6K9ubn5JMo2M7PBynqnqKQGsjAvRcSPBr+eB/zNeV8Bv8gfZmY2Rsq5y0XAd4AdEfGVYfpMk3RKvvrHwNNDjOLNzKyGyhmhXw7cCGzLp1Qgu6tlFkBEPAhcBHxf0mFgO3BLDWo1M7MTGDHQI2ItoBH6/Ax4d7WKMjOzyvmdomZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZWSIc6GZmiXCgm5klwoFuZpYIB7qZ2RgplaC1FSZNypalUnX3X9bnoZuZ2ckplaCzE/r6svU9e7J1qN53q3qEbmY2BpYvfzvMj+rry9qrxYFuZjYG9u6trH00HOhmZmNg1qzK2kfDgW5mNgZWrICmpuPbmpqy9mpxoJuZjYGODujqgtmzQcqWXV3VuyAKvsvFzGzMdHRUN8AH8wjdzCwRDnQzs0Q40M3MEuFANzNLhAPdzCwRiohiDiz1AntGufkM4OUqllMPfM4Tg895YjiZc54dEc1DvVBYoJ8MSd0R0V50HWPJ5zwx+Jwnhlqds6dczMwS4UA3M0tEvQZ6V9EFFMDnPDH4nCeGmpxzXc6hm5nZb6vXEbqZmQ3iQDczS0RdBbqk70raL+m5omsZK5LeKelJSTskPS/pjqJrqjVJjZLWS9qSn/PdRdc0FiRNlrRJ0qqiaxkrkl6UtE3SZkndRddTa5KmSXpM0s78//RlVd1/Pc2hS/p94BDw/YiYV3Q9Y0HSOcA5EbFR0lRgA3BtRGwvuLSakSTg9Ig4JKkBWAvcERHPFlxaTUn6b0A7cGZEfKjoesaCpBeB9oiYEG8skvQw8C8R8W1JpwBNEfFKtfZfVyP0iHga+I+i6xhLEbEvIjbmzw8CO4CZxVZVW5E5lK825I/6GXmMgqQW4IPAt4uuxWpD0pnA7wPfAYiI31QzzKHOAn2ik9QKXAKsK7aS2sunHzYD+4E1EZH6OX8N+O/AkaILGWMB/KOkDZI6iy6mxt4F9ALfy6fWvi3p9GoewIFeJySdAfwQ+ExEvFZ0PbUWEYcjYgHQAiyUlOwUm6QPAfsjYkPRtRTg8ohoA64BbsunVVM1BWgDvhURlwCvA8uqeQAHeh3I55F/CJQi4kdF1zOW8j9JnwKWFFxKLV0OfCSfT/4BsFjSI8WWNDYi4lf5cj/wY2BhsRXVVA/QM+CvzcfIAr5qHOjjXH6B8DvAjoj4StH1jAVJzZKm5c9PA64GdhZbVe1ExP+IiJaIaAWuA56IiBsKLqvmJJ2eX+gnn3p4P5DsHWwR8RLwS0kX5E1XAVW9uaGuviRa0qPAlcAMST3AX0TEd4qtquYuB24EtuVzygB3RsTfF1hTrZ0DPCxpMtmgY2VETJhb+SaQ3wV+nI1ZmAL8VUT8Q7El1dztQCm/w+XnwM3V3Hld3bZoZmbD85SLmVkiHOhmZolwoJuZJcKBbmaWCAe6mVkiHOhmZolwoJuZJeL/A6wM0eK0xUIvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history[\"loss\"]\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, \"bo\", label = \"Training loss\" )\n",
    "plt.title(\"Training loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
